<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Kaldi中的nnet3——Data types in the &quot;nnet3&quot; setup. | 追风的猪</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Kaldi中的nnet3——Data types in the &quot;nnet3&quot; setup.</h1><a id="logo" href="/.">追风的猪</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Kaldi中的nnet3——Data types in the &quot;nnet3&quot; setup.</h1><div class="post-meta">May 18, 2019<span> | </span><span class="category"><a href="/categories/kaldi/">kaldi</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a class="disqus-comment-count" href="/2019/05/18/Kaldi中的nnet3/#vcomment"><span class="valine-comment-count" data-xid="/2019/05/18/Kaldi中的nnet3/"></span><span> 条评论</span></a><div class="post-content"><blockquote>
<p>大部分翻译自kaldi的官网，以及自己的理解，如有错误还请指正</p>
</blockquote>
<h2 id="1、nnet3-outline"><a href="#1、nnet3-outline" class="headerlink" title="1、nnet3 outline"></a>1、nnet3 outline</h2><p>在nnet3中，使用一个通用的图结构，而不仅仅是一个组件序列，一个nnet3神经网络有下面两部分组成</p>
<ul>
<li>无序的Components列表，每个Components都有个name</li>
<li>一个图（graph）结构，有一个类似粘合剂的结构，指明怎么将Components组合在一起，或者说怎么构成这个图<blockquote>
<p>这里的图由一个个结点组成，每个结点表示神经网络中的某一层</p>
</blockquote>
</li>
</ul>
<p>图的结点通过Components的名字跟某个Component关联在一起，即通过Component的名字指明图的结点使用的是哪个Component。这种类似粘合剂的结构使得RNN得以工作，同时也使得我们可以处理边缘效应（edge effects， 可能发生在RNN中，比如RNN的0时刻，0时刻之前没有数据）。</p>
<p>当训练或者解码，一个神经网络的过程如下：</p>
<ul>
<li>用户提供一个ComputationRequest，说明可用输入的索引(例如时间索引)和请求的输出</li>
<li>ComputationRequest和神经网络一起被编译成一系列命令作为NnetComputing</li>
<li>NnetComputing进一步优化速度(可以认为这是编译器优化，就像gcc的-O标志一样)。</li>
<li>NnetComputer负责接收矩阵值输入，评估NnetComputing，并提供矩阵值输出。可以把这看作是一种非常有限的解释语言的运行时。</li>
</ul>
<p>Components和graph的配置文件如下所示：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> First the components</span></span><br><span class="line">component name=affine1 type=NaturalGradientAffineComponent input-dim=48 output-dim=65</span><br><span class="line">component name=relu1 type=RectifiedLinearComponent dim=65</span><br><span class="line">component name=affine2 type=NaturalGradientAffineComponent input-dim=65 output-dim=115</span><br><span class="line">component name=logsoftmax type=LogSoftmaxComponent dim=115</span><br><span class="line"><span class="meta">#</span><span class="bash"> Next the nodes</span></span><br><span class="line">input-node name=input dim=12</span><br><span class="line">component-node name=affine1_node component=affine1 input=Append(Offset(input, -1), Offset(input, 0), Offset(input, 1), Offset(input, 2))</span><br><span class="line">component-node name=nonlin1 component=relu1 input=affine1_node</span><br><span class="line">component-node name=affine2 component=affine2 input=nonlin1</span><br><span class="line">component-node name=output_nonlin component=logsoftmax input=affine2</span><br><span class="line">output-node name=output input=output_nonlin</span><br></pre></td></tr></table></figure></p>
<p>对于Components,可以看到Component中有个name属性对Component进行命名，每个Component都要指出input-dim和output-dim,当input-dim和output-dim相同时，则可以通过dim指出，表示input-dim和output-dim相同，同时通过type指明Component的类型。<br>图由input-node, component-node，output-node组成，其中component-node中通过component属性指明component,同时通过name对这个component-node进行命名，除此之外，component-node中还有一个input属性（暂时称为属性），这个input就是前面所提到的类似于粘合剂的结构，指明如何将Components组合在一起构成图，从上面可以看到，除了input和affine1_node,其他结点的input都是上一个component-node的名字，由此指明可Component之间如何组合构成图。</p>
<h2 id="2、Basic-data-structures-in-nnet3"><a href="#2、Basic-data-structures-in-nnet3" class="headerlink" title="2、Basic data structures in nnet3"></a>2、Basic data structures in nnet3</h2><h4 id="2-1、Index"><a href="#2-1、Index" class="headerlink" title="2.1、Index"></a>2.1、Index</h4><p>为了表示Component需要处理的输入矩阵，即Component的输入用一个矩阵表示，使用Index结构来索引矩阵的每一行。<br>Index是一个tuple(n, t, x), 其中n是minibatch的索引，即表示第n条数据，如果每个minibatch的大小为512，则0&lt;=n&lt;=511；t表示语音帧的索引，x是一个额外的索引，可能会在卷积神经网络中使用或者其他地方使用,大部分情况下为0。在神经网络的计算中，我们使用向量，比如，隐藏的激活层是一个1024维的向量，这就意味着有个矩阵的列数是1024，矩阵的行和Index是一一对应的。<br>当我们训练一个简单的前馈网络时，所有的Index可能只有n是不同的，因为没有时序信息。即<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ (0, 0, 0)  (1, 0, 0)  (2, 0, 0) ... ]</span><br></pre></td></tr></table></figure></p>
<p>当我们对一句简单的utterance进行解码,由于说话时序的，此时Index如下所示<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ (0, 0, 0)  (0, 1, 0)  (0, 2, 0) ... ]</span><br></pre></td></tr></table></figure></p>
<p>但我们在一个网络中使用时序上下文，其n和t都可能是不同的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ (0, -1, 0)  (0, 0, 0)  (0, 1, 0) (1, -1, 0) (1, 0, 0) (1, 1, 0) ... ]</span><br></pre></td></tr></table></figure></p>
<p>Index有一个默认的操作符，会依次根据n,t,x进行排序，当我们在代码中对这些vector进行打印时，我们通常看到的是其压缩的形式，其中x被省略了，t用一个范围表示，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ (0, -1:1) (1, -1:1) ... ]</span><br></pre></td></tr></table></figure></p>
<h4 id="2-2、CIndex"><a href="#2-2、CIndex" class="headerlink" title="2.2、CIndex"></a>2.2、CIndex</h4><p>CIndex是（int32, Index）的一对值，其中int32与网络的结点相对应，前面提到，一个神经网络由一系列的Component和Component-node组成，这里的int32就是与component-node的索引相对应。CIndex与一个特定的结点的输出相对应，通常情况下，CIndex和矩阵的行是一一对应的，与Index不同的是，CIndex除了会告诉我们矩阵的行，还会告诉我们来自哪个矩阵，比如一个affine1的结点，索引为2，输出是1000维的向量，CIndex(2,(0,0,0))则与一个列数为1000的矩阵的某些行对应。</p>
<h4 id="2-3、ComputationGraph"><a href="#2-3、ComputationGraph" class="headerlink" title="2.3、ComputationGraph"></a>2.3、ComputationGraph</h4><p>一个ComputationGraph通过CIndex表示一个有向图。每个Cindex都有一个其他CIndex的列表的信息，比如说，在一个简单的前馈网络结构中，为了表达清楚，这里使用名字而不是int32来表示一个结点，比如（nonlin1,(0,0,0)）依赖于（affine1,(0,0,0)）,nonlin1,(1,0,0)）依赖于（affine1,(1,0,0)）。在ComputationGraph和其他地方，您将看到名为cindex_id的整型变量。每个cindex_id是存储在图中的Cindex数组中的一个索引，它标识一个特定的Cindex;cindex_id用于提高效率，因为使用单个整数比使用Cindex更容易。</p>
<h4 id="2-4、ComputationRequest"><a href="#2-4、ComputationRequest" class="headerlink" title="2.4、ComputationRequest"></a>2.4、ComputationRequest</h4><p>一个ComputationRequest标志一组命名的输入和输出结点，每个结点都与一个Index列表关联。对于输入结点，Index列表标志哪些Index用来计算，对于输出结点，Index列表标志哪些Index需要计算，除此之外，ComputationRequest保存了一些标志，比如哪些输入输出需要计算或者提供反向传播的导数，模型模块是否需要更新。<br>例如，ComputationRequest可能指定有一个的输入结点，即Index列表 [(0，-1,0)，(0,0,0)，(0,1,0)];还有一个输出结点，即Index列表 [(0,0,0)]。因为对于语音来说，需要前后的上下文。实际上，我们通常只会在训练中像这样请求单独的输出帧;在训练过程中，我们通常在minibatch中有多条数据，所以索引的“n”维度也会有所不同。<br>目标函数及其导数的计算不属于核心神经网络框架;我们把这个留给用户。神经网络一般可以有多个输入和输出结点;这在多任务学习或处理多种不同类型输入数据的框架(例如多任务学习)中可能很有用。</p>
<h4 id="2-5、NnetComputation"><a href="#2-5、NnetComputation" class="headerlink" title="2.5、NnetComputation"></a>2.5、NnetComputation</h4><p>Nnetcomputing表示由Nnet和ComputationRequest编译生成的特定计算。它包含一系列命令，每个命令可以是一个传播操作、一个矩阵复制或添加操作，以及其他各种简单的矩阵命令，例如将特定行从一个矩阵复制到另一个矩阵;反向传播操作命令、矩阵大小调整命令等等。计算所作用的变量是一个矩阵列表，以及可能使用的矩阵行或列范围的子矩阵。</p>
<h4 id="2-6、NnetComputer"><a href="#2-6、NnetComputer" class="headerlink" title="2.6、NnetComputer"></a>2.6、NnetComputer</h4><p>NnetComputer对象负责实际执行Nnetcomputing。这段代码实际上非常简单(主要是一个带有switch语句的循环)，因为大部分复杂性发生在编译和优化Nnetcomputing期间。</p>
<h2 id="3、Neural-networks-in-nnet3"><a href="#3、Neural-networks-in-nnet3" class="headerlink" title="3、Neural networks in nnet3"></a>3、Neural networks in nnet3</h2><h4 id="3-1、Component"><a href="#3-1、Component" class="headerlink" title="3.1、Component"></a>3.1、Component</h4><p>对于nnet3中的Componnet, 有Propagate和Backprop两个最重要的方法，可能包含其他一些参数（比如affine layer）或者只是实现了一个固定的非线性函数（比如Sigmoid component）。Component类最重要的部分如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Component</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Propagate</span><span class="params">(<span class="keyword">const</span> ComponentPrecomputedIndexes *indexes,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">const</span> CuMatrixBase&lt;BaseFloat&gt; &amp;in,</span></span></span><br><span class="line"><span class="function"><span class="params">                         CuMatrixBase&lt;BaseFloat&gt; *out)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Backprop</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> &amp;debug_info,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">const</span> ComponentPrecomputedIndexes *indexes,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">const</span> CuMatrixBase&lt;BaseFloat&gt; &amp;in_value,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">const</span> CuMatrixBase&lt;BaseFloat&gt; &amp;out_value,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">const</span> CuMatrixBase&lt;BaseFloat&gt; &amp;out_deriv,</span></span></span><br><span class="line"><span class="function"><span class="params">                        Component *to_update, <span class="comment">// may be NULL; may be identical</span></span></span></span><br><span class="line"><span class="function"><span class="params">                                              <span class="comment">// to "this" or different.</span></span></span></span><br><span class="line"><span class="function"><span class="params">                        CuMatrixBase&lt;BaseFloat&gt; *in_deriv)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">   ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>每个确定的组件都有一个输入的维度和输出的维度，根据这些维度一行一行的进行转换数据，在Propagate()中的in和out则具有相同数目的行，input的每行处理之后生成output的行。这意味中输入和输出对应Index是一样的。在Backprop有相似的逻辑。<br>Component有一个虚函数会返回一个位掩码，包含可以各种二进制标志，这二进制标志定义在枚举ComponentProperties。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Component</span> &#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> int32 <span class="title">Properties</span><span class="params">()</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>定义的二进制标志<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ComponentProperties</span></span><br><span class="line"><span class="keyword">enum</span> ComponentProperties &#123;</span><br><span class="line">   kSimpleComponent = <span class="number">0x001</span>,  <span class="comment">// true if number of rows of input equals number of rows</span></span><br><span class="line">                              <span class="comment">// of output and this component doesn't care about the indexes</span></span><br><span class="line">                              <span class="comment">// (i.e. it maps each row of input to each row of output without</span></span><br><span class="line">                              <span class="comment">// regard to the index values).  Will normally be true.</span></span><br><span class="line">   kUpdatableComponent = <span class="number">0x002</span>,  <span class="comment">// true if the component has parameters that can</span></span><br><span class="line">                                 <span class="comment">// be updated.  Components that return this flag</span></span><br><span class="line">                                 <span class="comment">// must be dynamic_castable to type</span></span><br><span class="line">                                 <span class="comment">// UpdatableComponent (but components of type</span></span><br><span class="line">                                 <span class="comment">// UpdatableComponent do not have to return this</span></span><br><span class="line">                                 <span class="comment">// flag, e.g.  if this instance is not really</span></span><br><span class="line">                                 <span class="comment">// updatable).</span></span><br><span class="line">   kPropagateInPlace = <span class="number">0x004</span>,  <span class="comment">// true if we can do the propagate operation in-place</span></span><br><span class="line">                               <span class="comment">// (input and output matrices are the same).</span></span><br><span class="line">                               <span class="comment">// Note: if doing backprop, you'd also need to check</span></span><br><span class="line">                               <span class="comment">// that the kBackpropNeedsInput property is not true.</span></span><br><span class="line">   kPropagateAdds = <span class="number">0x008</span>,  <span class="comment">// true if the Propagate function adds to, rather</span></span><br><span class="line">                            <span class="comment">// than setting, its output, for non-in-place</span></span><br><span class="line">                            <span class="comment">// propagation.  The Component chooses whether to add</span></span><br><span class="line">                            <span class="comment">// or set, and the calling code has to accommodate</span></span><br><span class="line">                            <span class="comment">// it.</span></span><br><span class="line">   kReordersIndexes = <span class="number">0x010</span>,  <span class="comment">// true if the ReorderIndexes function might reorder</span></span><br><span class="line">                              <span class="comment">// the indexes (otherwise we can skip calling it).</span></span><br><span class="line">                              <span class="comment">// Must not be set for simple components.</span></span><br><span class="line">   kBackpropAdds = <span class="number">0x020</span>,   <span class="comment">// true if the Backprop function adds to, rather than</span></span><br><span class="line">                            <span class="comment">// setting, the "in_deriv" output for non-in-place</span></span><br><span class="line">                            <span class="comment">// backprop.  The Component chooses whether to add or</span></span><br><span class="line">                            <span class="comment">// set, and the calling code has to accommodate it.</span></span><br><span class="line">   kBackpropNeedsInput = <span class="number">0x040</span>,  <span class="comment">// true if backprop operation needs access to</span></span><br><span class="line">                                 <span class="comment">// forward-pass input.</span></span><br><span class="line">   kBackpropNeedsOutput = <span class="number">0x080</span>,  <span class="comment">// true if backprop operation needs access to</span></span><br><span class="line">                                  <span class="comment">// forward-pass output (e.g. true for Sigmoid).</span></span><br><span class="line">   kBackpropInPlace = <span class="number">0x100</span>,   <span class="comment">// true if we can do the backprop operation in-place</span></span><br><span class="line">                              <span class="comment">// (input and output matrices may be the same).</span></span><br><span class="line">   kStoresStats = <span class="number">0x200</span>,      <span class="comment">// true if the StoreStats operation stores</span></span><br><span class="line">                              <span class="comment">// statistics e.g. on average node activations and</span></span><br><span class="line">                              <span class="comment">// derivatives of the nonlinearity, (as it does for</span></span><br><span class="line">                              <span class="comment">// Tanh, Sigmoid, ReLU and Softmax).</span></span><br><span class="line">   kInputContiguous = <span class="number">0x400</span>,  <span class="comment">// true if the component requires its input data (and</span></span><br><span class="line">                               <span class="comment">// input derivatives) to have Stride()== NumCols().</span></span><br><span class="line">   kOutputContiguous = <span class="number">0x800</span>,  <span class="comment">// true if the component requires its input data (and</span></span><br><span class="line">                                <span class="comment">// output derivatives) to have Stride()== NumCols().</span></span><br><span class="line">   kUsesMemo = <span class="number">0x1000</span>,  <span class="comment">// true if the component returns a void* pointer from its</span></span><br><span class="line">                        <span class="comment">// Propagate() function that needs to be passed into the</span></span><br><span class="line">                        <span class="comment">// corresponding Backprop function.</span></span><br><span class="line">   kRandomComponent = <span class="number">0x2000</span>   <span class="comment">// true if the component has some kind of</span></span><br><span class="line">                               <span class="comment">// randomness, like DropoutComponent (these should</span></span><br><span class="line">                               <span class="comment">// inherit from class RandomComponent.</span></span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure></p>
<p>这些属性标识组件的各种特征，比如它是否包含可更新参数(kUpdatableComponent)、它的propagate函数是否支持就地操作(kpropagation inplace)以及其他各种东西。这些大部分属性在进行优化的过程中使用，所以从这里可以知道哪些优化是可用的。您还将注意到属性kSimpleComponent。如果设置了，则组件是“simple”，这意味着它将按照上面定义的那样逐行转换数据。non-simple组件可能允许不同行数的输入和输出，并且可能需要知道在输入和输出中使用什么索引。Progate和Backprop的const ComponentPrecomputedIndexes *indexes参数仅供非简单组件使用。<br>现在，请假设所有组件都是simple的，因为我们还没有实现任何non-simple组件，并且因为实现任何标准方法(RNNs、LSTMs等等)都不需要它们。与nnet2框架不同，组件不负责实现跨帧的拼接;相反，我们使用 Descriptors来处理它，如下所述。</p>
<h4 id="3-2、Component-node"><a href="#3-2、Component-node" class="headerlink" title="3.2、Component-node"></a>3.2、Component-node</h4><p>我们之前解释过，神经网络是一组命名的组件和一个关于“网络结点”的图，但是我们还没有解释什么是“网络结点”。NetworkNode实际上是一个结构体。NetworkNode可以是四种不同类型中的一种，由NodeType enum定义:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> NodeType &#123; kInput, kDescriptor, kComponent, kDimRange &#125;;</span><br></pre></td></tr></table></figure></p>
<p>其中最重要的三个是kInput、kDescriptor和kComponent(kDimRange支持将结点的输出分割成不同的部分)。kComponent结点是网络的“肉”，而Descriptor(冒着混合隐喻的风险)则是将其连接在一起的“胶水”，支持帧拼接和递归等操作。kInput结点非常简单，只提供一个地方来转储所提供的输入并声明其维度;他们什么都不做。您可能会惊讶于没有kOutput结点。原因是输出结点只是Descriptor。有一个规则，kComponent类型的每个结点必须在结点列表的前面紧跟着它自己的kDescriptor类型的结点;即每个kComponent类型的结点都必须在它的kDescriptor类型结点的后面。因此，一个类型为kDescriptor的结点如果没有立即紧接一个kComponent结点，则该结点将被绑定为一个输出结点;</p>
<h4 id="3-3、Neural-network-config-file"><a href="#3-3、Neural-network-config-file" class="headerlink" title="3.3、Neural network config file"></a>3.3、Neural network config file</h4><p>Neural network可以从配置文件创建。我们在这里给出一个非常简单的例子来说明配置文件如何与Descriptors相关联。这个网络有一个隐藏层，并在第一个结点上随着时间进行拼接:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First the components</span></span><br><span class="line">component name=affine1 <span class="built_in">type</span>=NaturalGradientAffineComponent input-dim=48 output-dim=65</span><br><span class="line">component name=relu1 <span class="built_in">type</span>=RectifiedLinearComponent dim=65</span><br><span class="line">component name=affine2 <span class="built_in">type</span>=NaturalGradientAffineComponent input-dim=65 output-dim=115</span><br><span class="line">component name=logsoftmax <span class="built_in">type</span>=LogSoftmaxComponent dim=115</span><br><span class="line"><span class="comment"># Next the nodes</span></span><br><span class="line">input-node name=input dim=12</span><br><span class="line">component-node name=affine1_node component=affine1 input=Append(Offset(input, -1), Offset(input, 0), Offset(input, 1), Offset(input, 2))</span><br><span class="line">component-node name=nonlin1 component=relu1 input=affine1_node</span><br><span class="line">component-node name=affine2 component=affine2 input=nonlin1</span><br><span class="line">component-node name=output_nonlin component=logsoftmax input=affine2</span><br><span class="line">output-node name=output input=output_nonlin</span><br></pre></td></tr></table></figure></p>
<p>在配置文件中没有对Descriptors的引用(例如，没有“descriptors-node”)。相反，“input”字段(例如input =Append(…))是Descriptors。配置文件中的每个组件结点都被扩展为两个结点:一个是kComponent类型的结点，另一个是“input”字段定义的紧接在前面的kDescriptor类型的结点。<br>上面的配置文件没有给出dim-range结点的示例。dim-range结点的基本格式是这样的(本例将从组件affine1的65个维度中选取前50个维度):<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dim-range-node name=dim-range-node1 input-node=affine1_node dim-offset=0 dim=50</span><br></pre></td></tr></table></figure></p>
<h4 id="3-4、Descriptors-in-config-files"><a href="#3-4、Descriptors-in-config-files" class="headerlink" title="3.4、Descriptors in config files"></a>3.4、Descriptors in config files</h4><p>描述符是一种非常有限的表达式类型，它引用图中其他结点中定义的变量。描述符是将组件连接在一起的粘合剂的一部分，它们负责对组件的输出扩展或求和，以便它们可以用作以后组件的输入。在本结中，我们将从配置文件格式的角度描述描述符;下面我们将解释它们如何出现在代码中。<br>最简单的描述符类型(基本情况)只是一个结点名，例如“affine1”(这里只允许出现kComponent或kInput类型的结点，以简化实现)。我们将在下面列出描述符中可能出现的一些类型的表达式，但是请记住，这个描述将为您提供描述符的样子，它比实际情况更一般;实际上，这些可能只出现在某个层次结构中，我们将在本页后面更精确地描述它。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> caution, this is a simplification that overgenerates descriptors.</span></span><br><span class="line">&lt;descriptor&gt;  ::=   &lt;node-name&gt;      ;; node name of kInput or kComponent node.</span><br><span class="line">&lt;descriptor&gt;  ::=   Append(&lt;descriptor&gt;, &lt;descriptor&gt; [, &lt;descriptor&gt; ... ] )</span><br><span class="line">&lt;descriptor&gt;  ::=   Sum(&lt;descriptor&gt;, &lt;descriptor&gt;)</span><br><span class="line">&lt;descriptor&gt;  ::=   Const(&lt;value&gt;, &lt;dimension&gt;)    ;; e.g. Const(1.0, 512)</span><br><span class="line">&lt;descriptor&gt;  ::=   Scale(&lt;scale&gt;, &lt;descriptor&gt;)   ;; e.g. Scale(-1.0, tdnn2)</span><br><span class="line">;; Failover or IfDefined might be useful for time t=-1 in a RNN, for instance.</span><br><span class="line">&lt;descriptor&gt;  ::=   Failover(&lt;descriptor&gt;, &lt;descriptor&gt;)   ;; 1st arg if computable, else 2nd</span><br><span class="line">&lt;descriptor&gt;  ::=   IfDefined(&lt;descriptor&gt;)     ;; the arg if defined, else zero.</span><br><span class="line">&lt;descriptor&gt;  ::=   Offset(&lt;descriptor&gt;, &lt;t-offset&gt; [, &lt;x-offset&gt; ] ) ;; offsets are integers</span><br><span class="line">;; Switch(...) is intended to be used in clockwork RNNs or similar schemes.  It chooses</span><br><span class="line">;; one argument based on the value of t (in the requested Index) modulo the number of</span><br><span class="line">;; arguments</span><br><span class="line">&lt;descriptor&gt;  ::=   Switch(&lt;descriptor&gt;, &lt;descriptor&gt; [, &lt;descriptor&gt; ...])</span><br><span class="line">;; For use in clockwork RNNs or similar, Round() rounds the time-index t of the</span><br><span class="line">;; requested Index to the next-lowest multiple of the integer &lt;t-modulus&gt;,</span><br><span class="line">;; and evaluates the input argument for the resulting Index.</span><br><span class="line">&lt;descriptor&gt;  ::=   Round(&lt;descriptor&gt;, &lt;t-modulus&gt;)  ;; &lt;t-modulus&gt; is an integer</span><br><span class="line">;; ReplaceIndex replaces some &lt;variable-name&gt; (t or x) in the requested Index</span><br><span class="line">;; with a fixed integer &lt;value&gt;.  E.g. might be useful when incorporating</span><br><span class="line">;; iVectors; iVector would always have time-index t=0.</span><br><span class="line">&lt;descriptor&gt;  ::=   ReplaceIndex(&lt;descriptor&gt;, &lt;variable-name&gt;, &lt;value&gt;)</span><br></pre></td></tr></table></figure></p>
<p>现在我们将描述代码内部使用的实际语法，这与上面的简化版本不同，因为表达式可能只出现在特定的层次结构中。这种语法也更接近于实际代码中的类名。读取描述符的代码试图以一种尽可能通用的方式对它们进行规范化，以便几乎所有上述语法都可以被读取并转换为内部表示。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">;;; &lt;descriptor&gt; == class Descriptor</span><br><span class="line">&lt;descriptor&gt; ::=  Append(&lt;sum-descriptor&gt;[, &lt;sum-descriptor&gt; ... ] )</span><br><span class="line">&lt;descriptor&gt; ::=  &lt;sum-descriptor&gt;  ;; equivalent to Append() with one arg.</span><br><span class="line">;;; &lt;sum-descriptor&gt; == class SumDescriptor</span><br><span class="line">&lt;sum-descriptor&gt; ::= Sum(&lt;sum-descriptor&gt;, &lt;sum-descriptor&gt;)</span><br><span class="line">&lt;sum-descriptor&gt; ::= Failover(&lt;sum-descriptor&gt;, &lt;sum-descriptor&gt;)</span><br><span class="line">&lt;sum-descriptor&gt; ::= IfDefined(&lt;sum-descriptor&gt;)</span><br><span class="line">&lt;sum-descriptor&gt; ::= Const(&lt;value&gt;, &lt;dimension&gt;)</span><br><span class="line">&lt;sum-descriptor&gt; ::= &lt;fwd-descriptor&gt;</span><br><span class="line">;;; &lt;fwd-descriptor&gt; == class ForwardingDescriptor</span><br><span class="line">;; &lt;t-offset&gt; and &lt;x-offset&gt; are integers.</span><br><span class="line">&lt;fwd-descriptor&gt;  ::=   Offset(&lt;fwd-descriptor&gt;, &lt;t-offset&gt; [, &lt;x-offset&gt; ] )</span><br><span class="line">&lt;fwd-descriptor&gt;  ::=   Switch(&lt;fwd-descriptor&gt;, &lt;fwd-descriptor&gt; [, &lt;fwd-descriptor&gt; ...])</span><br><span class="line">;; &lt;t-modulus&gt; is an integer</span><br><span class="line">&lt;fwd-descriptor&gt;  ::=   Round(&lt;fwd-descriptor&gt;, &lt;t-modulus&gt;)</span><br><span class="line">;; &lt;variable-name&gt; is t or x; &lt;value&gt; is an integer</span><br><span class="line">&lt;fwd-descriptor&gt;  ::=   ReplaceIndex(&lt;fwd-descriptor&gt;, &lt;variable-name&gt;, &lt;value&gt;)</span><br><span class="line">;; &lt;node-name&gt; is the name of a node of type kInput or kComponent.</span><br><span class="line">&lt;fwd-descriptor&gt;  ::=   Scale(&lt;scale&gt;, &lt;node-name&gt;)</span><br><span class="line">&lt;fwd-descriptor&gt;  ::=   &lt;node-name&gt;</span><br></pre></td></tr></table></figure></p>
<p>描述符的设计应该有足够的限制，这样得到的表达式将相当容易计算(并生成反向传播代码)。当涉及到将组件连接在一起时，它们只应该只是heavy lifting，而任何更有趣或非线性的操作都应该在组件本身中执行。<br>注意:如果有必要对各种长度未知的索引(例如文件中的所有“t”值)进行求和或求平均值，我们打算在组件(非简单组件)中进行，而不是使用Descriptor。</p>
<h4 id="3-5、Descriptors-in-code"><a href="#3-5、Descriptors-in-code" class="headerlink" title="3.5、Descriptors in code"></a>3.5、Descriptors in code</h4><p>我们将自底向上描述代码中的Descriptors 。基类ForwardingDescriptor 处理只引用单个值的Descriptor类型，没有任何Append(…)或Sum(…)表达式之类的。这个接口中最重要的函数是MapToInput():<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ForwardingDescriptor</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Cindex <span class="title">MapToInput</span><span class="params">(<span class="keyword">const</span> Index &amp;output)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>这个函数，给定一个请求的Index,返回一个CIndex。有几个ForwardingDescriptor 的派生类，包括SimpleForwardingDescriptor(基本情况，只包含一个结点索引)、OffsetForwardingDescriptor、ReplaceindexForwardingDescriptor等。<br>接下来是SumDescriptor,它支持表达式Sum(<desc>, <desc>), Failover(<desc>, <desc>)和IfDefined(<desc>)。显然，对SumDescriptor的给定Index的请求可能返回几个不同的Cindexes，所以我们用于ForwardingDescriptor 的接口不能工作。我们还需要支持可选依赖项。下面是我们如何在代码层管理它:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SumDescriptor</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">GetDependencies</span><span class="params">(<span class="keyword">const</span> Index &amp;ind,</span></span></span><br><span class="line"><span class="function"><span class="params">                               <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Cindex&gt; *dependencies)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></desc></desc></desc></desc></desc></p>
<p>函数GeyDependencies将添加所有可能涉及到这个Index计算的CIndex到dependecies中去。接下来，我们需要担心当某些请求的输入可能无法计算时会发生什么情况(例如，由于输入数据有限或边缘效应)。函数IsComputable()处理这个问题:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SumDescriptor</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">bool</span> <span class="title">IsComputable</span><span class="params">(<span class="keyword">const</span> Index &amp;ind,</span></span></span><br><span class="line"><span class="function"><span class="params">                            <span class="keyword">const</span> CindexSet &amp;cindex_set,</span></span></span><br><span class="line"><span class="function"><span class="params">                            <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Cindex&gt; *input_terms)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>在这里，CindexSet对象是一组Cindexes的表示，在此上下文中，表示“我们知道的所有可计算Cindex的集合”。如果这个Index的Descriptor是可计算的，函数将返回true。例如，表达式Sum(X, Y)只有在X和Y可计算时才可计算。如果这个函数将返回true，那么它还将只向“input_terms”追加实际出现在求值表达式中的输入Cindexes。例如，在Failover(X, Y)的表达式中，如果X是可计算的，那么只有X会被加入到input_terms中，而Y不会。</p>
<h2 id="4、more-detail"><a href="#4、more-detail" class="headerlink" title="4、more detail"></a>4、more detail</h2><h4 id="4-1、Neural-network-nodes-detail"><a href="#4-1、Neural-network-nodes-detail" class="headerlink" title="4.1、Neural network nodes (detail)"></a>4.1、Neural network nodes (detail)</h4><p>现在我们将更详细地描述神经网络结点。如上所述，enum定义了四种类型的结点kInput, kDescriptor, kComponent, kDimRange。<br>实际的NetworkNode是一个结构体。为了避免指针的麻烦，因为c++不允许包含类的union，所以我们的布局有点乱:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">NetworkNode</span> &#123;</span></span><br><span class="line">  NodeType node_type;</span><br><span class="line">  <span class="comment">// "descriptor" is relevant only for nodes of type kDescriptor.</span></span><br><span class="line">  Descriptor descriptor;</span><br><span class="line">  <span class="keyword">union</span> &#123;</span><br><span class="line">    <span class="comment">// For kComponent, the index into Nnet::components_</span></span><br><span class="line">    int32 component_index;</span><br><span class="line">    <span class="comment">// for kDimRange, the node-index of the input node.</span></span><br><span class="line">    int32 node_index;</span><br><span class="line">  &#125; u;</span><br><span class="line">  <span class="comment">// for kInput, the dimension of the input feature.  For kDimRange, the dimension</span></span><br><span class="line">  <span class="comment">// of the output (i.e. the length of the range)</span></span><br><span class="line">  int32 dim;</span><br><span class="line">  <span class="comment">// for kDimRange, the dimension of the offset into the input component's feature.</span></span><br><span class="line">  int32 dim_offset;</span><br><span class="line">&#125;;</span><br><span class="line">`</span><br></pre></td></tr></table></figure></p>
<p>总结不同类型的结点及其实际使用的成员:</p>
<ul>
<li>kInput结点只使用“dim”</li>
<li>kDescriptor结点只使用“descriptor”</li>
<li>kComponent结点只使用“component_index”，后者索引Nnet的components_数组。</li>
<li>kDimRange结点只使用“node_index”、“dim”和“dim_offset”。</li>
</ul>
<h4 id="4-2、Neural-network-detail"><a href="#4-2、Neural-network-detail" class="headerlink" title="4.2、Neural network (detail)"></a>4.2、Neural network (detail)</h4><p>我们将更详细地介绍类Nnet本身，它存储整个神经网络。最简单的解释方法就是列出私有数据成员:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Nnet</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  ...</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt; component_names_;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Component*&gt; components_;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt; node_names_;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;NetworkNode&gt; nodes_;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>component_names_应具有与components_相同的大小，而node_names_应具有与nodes_相同的大小;这些名称与组件和结点相关联。注意，通过在对应组件结点的名称后面附加“_input”,<br>我们自动为kDescriptor类型的结点分配名称，这些结点位于对应的kComponent类型结点之前。kDescriptor结点的这些名称不会出现在神经网络的配置文件表示中。</p>
<h4 id="4-3、NnetComputation-detail"><a href="#4-3、NnetComputation-detail" class="headerlink" title="4.3、NnetComputation (detail)"></a>4.3、NnetComputation (detail)</h4><p>另一种重要的数据类型是结构体NnetComputing。这表示编译后的神经网络计算，包含一系列命令以及解释这些命令所需的其他信息。它在内部定义了许多类型，包括以下enum值:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> CommandType &#123;</span><br><span class="line">    kAllocMatrixUndefined, kAllocMatrixZeroed,</span><br><span class="line">    kDeallocMatrix, kPropagate, kStoreStats, kBackprop,</span><br><span class="line">    kMatrixCopy, kMatrixAdd, kCopyRows, kAddRows,</span><br><span class="line">    kCopyRowsMulti, kCopyToRowsMulti, kAddRowsMulti, kAddToRowsMulti,</span><br><span class="line">    kAddRowRanges, kNoOperation, kNoOperationMarker &#125;;</span><br></pre></td></tr></table></figure></p>
<p>我们想突出kPropagate、kBackprop和kMatrixCopy作为命令的自解释示例。有一个Command的结构体，它表示一个命令及其参数。大多数参数都是矩阵和组件列表中的索引。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Command</span> &#123;</span></span><br><span class="line">   CommandType command_type;</span><br><span class="line">   int32 arg1;</span><br><span class="line">   int32 arg2;</span><br><span class="line">   int32 arg3;</span><br><span class="line">   int32 arg4;</span><br><span class="line">   int32 arg5;</span><br><span class="line">   int32 arg6;</span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure></p>
<p>还定义了一些结构类型，用于存储矩阵和子矩阵的大小信息。子矩阵是一个可能受限制的矩阵行和列范围，如matlab语法some_matrix(1:10, 1:20):<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MatrixInfo</span> &#123;</span></span><br><span class="line">   int32 num_rows;</span><br><span class="line">   int32 num_cols;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="class"><span class="keyword">struct</span> <span class="title">SubMatrixInfo</span> &#123;</span></span><br><span class="line">   int32 matrix_index;  <span class="comment">// index into "matrices": the underlying matrix.</span></span><br><span class="line">   int32 row_offset;</span><br><span class="line">   int32 num_rows;</span><br><span class="line">   int32 col_offset;</span><br><span class="line">   int32 num_cols;</span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure></p>
<p>结构体NnetComputing的数据成员包括:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Command</span> &#123;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Command&gt; commands;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;MatrixInfo&gt; matrices;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;SubMatrixInfo&gt; submatrices;</span><br><span class="line">  <span class="comment">// used in kAddRows, kAddToRows, kCopyRows, kCopyToRows.  contains row-indexes.</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; &gt; indexes;</span><br><span class="line">  <span class="comment">// used in kAddRowsMulti, kAddToRowsMulti, kCopyRowsMulti, kCopyToRowsMulti.</span></span><br><span class="line">  <span class="comment">// contains pairs (sub-matrix index, row index)- or (-1,-1) meaning don't</span></span><br><span class="line">  <span class="comment">// do anything for this row.</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;int32,int32&gt; &gt; &gt; indexes_multi;</span><br><span class="line">  <span class="comment">// Indexes used in kAddRowRanges commands, containing pairs (start-index,</span></span><br><span class="line">  <span class="comment">// end-index)</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;int32,int32&gt; &gt; &gt; indexes_ranges;</span><br><span class="line">  <span class="comment">// Information about where the values and derivatives of inputs and outputs of</span></span><br><span class="line">  <span class="comment">// the neural net live.</span></span><br><span class="line">  <span class="built_in">unordered_map</span>&lt;int32, <span class="built_in">std</span>::pair&lt;int32, int32&gt; &gt; input_output_info;</span><br><span class="line">  <span class="keyword">bool</span> need_model_derivative;</span><br><span class="line">  <span class="comment">// the following is only used in non-simple Components; ignore for now.</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;ComponentPrecomputedIndexes*&gt; component_precomputed_indexes;</span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>名称中带有“indexes”的向量是矩阵函数的参数，如CopyRows、AddRows等，这些函数需要索引向量作为输入(我们将在执行计算之前将这些向量复制到GPU卡)。</p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>追风的猪</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/05/18/Kaldi中的nnet3/">http://joefi.github.io/2019/05/18/Kaldi中的nnet3/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><div class="tags"><a href="/tags/kaldi-nnet3/">kaldi nnet3</a></div><div class="post-nav"><a class="next" href="/2019/05/17/Kaldi的编译过程-makefile/">Kaldi的编译过程-makefile</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'EpW4PIfxM4lnev23BejpJKx7-gzGzoHsz',
  appKey:'2rvFbqd5gcnWYpcGVjVvNRcn',
  placeholder:'Just so so',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"><input type="hidden" name="sitesearch" value="http://joefi.github.io"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/kaldi/">kaldi</a><span class="category-list-count">3</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/kaldi-debug/" style="font-size: 15px;">kaldi debug</a> <a href="/tags/kaldi/" style="font-size: 15px;">kaldi</a> <a href="/tags/kaldi-nnet3/" style="font-size: 15px;">kaldi nnet3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/05/18/Kaldi中的nnet3/">Kaldi中的nnet3——Data types in the "nnet3" setup.</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/17/Kaldi的编译过程-makefile/">Kaldi的编译过程-makefile</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/17/阅读和修改kaldi的代码/">阅读和修改kaldi的代码</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">追风的猪.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>